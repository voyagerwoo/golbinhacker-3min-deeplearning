{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Convolution Neural Network\n",
    "\n",
    "cnn은 기본적으로 컨볼루션 계층(convolution layer, 합성곱 계층)과 풀링 계층(pooling layer)으로 구성된다. (2D 컨볼루션의 경우) 컨볼루션 계층과 풀링 계층 모두 2차원 평면 행렬에서 지정한 영역의 값들을 하나의 값으로 압축하는 것이다. 차이는 컨볼루션 계층은 가중치와 편향을 적용하여 하나의 값으로 압축하고, 풀링은 단순히 값중 하나를 선택해서 가져온다. \n",
    "\n",
    "- 윈도우 `Window`: 지정한 크기의 영역\n",
    "- 스트라이드 `Stride`: 몇칸 씩 움직일지 여부\n",
    "- 커널 또는 필터 `Kerner` or `Filter`: 컨볼루션을 적용할 때 사용할 윈도우 크기 만큼의 가중치와 1개의 편향\n",
    "- 컨볼루션 `Convolution`: 윈도우 사이즈 만큼 가중치와 편향을 적용하여 압축\n",
    "- 풀링 `Pooling`: 윈도우 사이즈 내의 값 중에서 하나의 값을 선택하여 압축 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-79dd1ec95eac>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/yeomyeongwoo/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 만든 모델에서는 28*28=784 짜리 차원 하나로 구성했지만, CNN 모델에서는 2차원 평면으로 구성하므로 위 처럼 좀 더 직관적인 형태로 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  Tensor(\"Placeholder_3:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "C1 :  Tensor(\"Relu_3:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "L1 :  Tensor(\"MaxPool_2:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 1st layer\n",
    "# Convolution Layer\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "C1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
    "C1 = tf.nn.relu(C1)\n",
    "\n",
    "# Pooling Layer\n",
    "L1 = tf.nn.max_pool(C1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "print('X : ', X)\n",
    "print('C1 : ', C1)\n",
    "print('L1 : ', L1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "\n",
    "- 3 x 3 크기의 커널을 32개 만듬\n",
    "- 오른쪽과 아랫쪽으로 한칸씩 움직이는(stride) 32개의 커널을 가짐\n",
    "- `padding='SAME'` : 커널 슬라이딩 시 이미지의 가장 외곽에서 한칸 밖으로 움직이는 옵션, 테두리도 좀더 명확하게 평가 가능\n",
    "\n",
    "### Pooling Layer\n",
    "- `ksize=[1,2,2,1]` : 커널 크기가 2 x 2인 풀링 계층을 만든다.\n",
    "- `strides=[1,2,2,1]` : 커널 슬라이딩시 두칸씩 움직이겠다는 옵션\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2 :  Tensor(\"Relu_4:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "L2 :  Tensor(\"MaxPool_3:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2nd Layer\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "C2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "C2 = tf.nn.relu(C2)\n",
    "L2 = tf.nn.max_pool(C2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "print('C2 : ', C2)\n",
    "print('L2 : ', L2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `[3, 3, 32, 64]` : 32 - 앞서 구성한 컨볼루션 커널 개수, 64 - 현재 레이어 커널개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Layer\n",
    "W3 = tf.Variable(tf.random_normal([7*7*64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 10개 분류는 1차원 배열(0~9)이므로 차원을 줄이는 단계를 거쳐야합니다.\n",
    "2. 직전 풀링 계층의 크기가 7*7*64 이므로, 먼저 tf.reshape 함수를 이용해 1차원 계층으로 만들고 256개의 뉴런으로 연결되는 신경망을 만들어준다.\n",
    "\n",
    "참고로 이처럼 인접한 계층의 모든 뉴런과 상호 연결된 계층을 완전 연결 계층 `fully connected layer`라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "# opt = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size : 100\n",
      "total batch size : 550\n",
      "Epoch: 0001 Avg. cost = 0.330\n",
      "Epoch: 0002 Avg. cost = 0.102\n",
      "Epoch: 0003 Avg. cost = 0.071\n",
      "Epoch: 0004 Avg. cost = 0.053\n",
      "Epoch: 0005 Avg. cost = 0.044\n",
      "Epoch: 0006 Avg. cost = 0.037\n",
      "Epoch: 0007 Avg. cost = 0.031\n",
      "Epoch: 0008 Avg. cost = 0.027\n",
      "Epoch: 0009 Avg. cost = 0.024\n",
      "Epoch: 0010 Avg. cost = 0.021\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "print('batch size : %s' % batch_size)\n",
    "print('total batch size : %s' % total_batch)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        _, cost_val = sess.run([opt, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch: %04d' % (epoch + 1), 'Avg. cost = {:.3f}'.format(total_cost/total_batch))\n",
    "\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `batch_xs = batch_xs.reshape(-1, 28, 28, 1)` : 입력데이터를 재구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9882\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, axis=1), tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('Accuracy : %s' % sess.run(accuracy, \n",
    "                                 feed_dict={X: mnist.test.images.reshape(-1,28,28,1), Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mnist.test.images.reshape(-1,28,28,1)` : 입력데이터 재구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
